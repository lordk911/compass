hadoop:
  namenodes:
    - nameservices: nsdev
      namenodesAddr: [ "hdpdev248.glodondg.com", "hdpdev244.glodondg.com" ]
      namenodes: [ "nn1", "nn2" ]
      user: hdfs
      password:
      port: 8020
      # scheduler platform hdfs log path keyword identification, used by task-application
      matchPathKeys: [ "flume" ]
      # kerberos
      enableKerberos: false
      # /etc/krb5.conf
      krb5Conf: ""
      # hdfs/*@EXAMPLE.COM
      principalPattern:  ""
      # admin
      loginUser: ""
      # /var/kerberos/krb5kdc/admin.keytab
      keytabPath: ""

  yarn:
    - clusterName: "bigdata"
      resourceManager: [ "hdpdev244.glodondg.com:8088", "hdpdev248.glodondg.com:8088" ]
      jobHistoryServer: "hdpdev244.glodondg.com:19888"

  spark:
    sparkHistoryServer: [ "hdpdev248.glodondg.com:18081" ]
